{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36781e83ede3a63b",
   "metadata": {},
   "source": [
    "# Recognition   "
   ]
  },
  {
   "cell_type": "code",
   "id": "58ba418d-5428-413c-8f19-d0c8feff7786",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T12:34:58.673702Z",
     "start_time": "2024-05-28T12:34:57.805664Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "repo_path = '/content/Cybathlon'\n",
    "git_url = 'https://Leonpa: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@github.com/Leonpa/Cybathlon.git'\n",
    "base_path = '/content/drive/MyDrive/Cybathlon'\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    from google.colab import drive\n",
    "    print('Running on CoLab')\n",
    "    if os.path.exists(repo_path):\n",
    "        print('Repository already cloned. Pulling changes...')\n",
    "        %cd $repo_path\n",
    "        !git reset --hard\n",
    "        !git pull\n",
    "        %cd /content\n",
    "    else:\n",
    "        print('Cloning repository for the first time...')\n",
    "        !git clone $git_url\n",
    "\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    sys.path.append(repo_path)\n",
    "\n",
    "    # gpu_info = !nvidia-smi\n",
    "    # gpu_info = '\\n'.join(gpu_info)\n",
    "    # if gpu_info.find('failed') >= 0:\n",
    "    #   print('Not connected to a GPU')\n",
    "    # else:\n",
    "    #   print(gpu_info)\n",
    "else:\n",
    "    print('Running locally')\n",
    "    base_path = ''\n",
    "\n",
    "sys.path.append('/content/Cybathlon/')\n",
    "from models.detection import Model, ModelTrainer, CustomDataset, Inference"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "5f89e850d6eb361c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T12:37:47.620802Z",
     "start_time": "2024-05-28T12:37:47.542640Z"
    }
   },
   "source": [
    "def prepare_dataloaders(data_dirs, batch_size=32, valid_split=0.1, test_split=0.1):\n",
    "    all_images = []\n",
    "    for data_dir in data_dirs:\n",
    "        all_images += glob.glob(os.path.join(data_dir, 'imgs_and_labels', 'images', '*.jpg'))\n",
    "\n",
    "    # Filter images to include only those that have corresponding labels\n",
    "    all_images = [img for img in all_images if os.path.exists(img.replace('images', 'labels').replace('.jpg', '.txt'))]\n",
    "\n",
    "    print(f\"Total images after filtering: {len(all_images)}\")\n",
    "    \n",
    "    random.shuffle(all_images)\n",
    "    total_images = len(all_images)\n",
    "    test_size = int(total_images * test_split)\n",
    "    valid_size = int(total_images * valid_split)\n",
    "    train_size = total_images - test_size - valid_size\n",
    "\n",
    "    train_images = all_images[:train_size]\n",
    "    valid_images = all_images[train_size:train_size + valid_size]\n",
    "    test_images = all_images[train_size + valid_size:]\n",
    "\n",
    "    print(f\"Training images: {len(train_images)}\")\n",
    "    print(f\"Validation images: {len(valid_images)}\")\n",
    "    print(f\"Test images: {len(test_images)}\")\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    train_dataset = CustomDataset(train_images, transform=transform)\n",
    "    valid_dataset = CustomDataset(valid_images, transform=transform)\n",
    "    test_dataset = CustomDataset(test_images, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, valid_loader, test_loader"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "9256c2085a5d29e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T12:37:50.576012Z",
     "start_time": "2024-05-28T12:37:50.554396Z"
    }
   },
   "source": [
    "# Define the data directories\n",
    "data_dirs = [\n",
    "    'data/real_1geo_bright_512867' #,\n",
    "    # 'data/real_1geo_onlyflash_512875',\n",
    "    # 'data/real_2geos_bright_512830',\n",
    "    # 'data/real_2geos_onlyflash_512887',\n",
    "    # 'data/real_3geos_bright_512712',\n",
    "    # 'data/real_4geos_bright_512639',\n",
    "    # 'data/real_4geos_onlyflash_512894'\n",
    "]\n",
    "full_paths = (os.path.join(base_path, dir) for dir in data_dirs)\n",
    "data_dirs = list(full_paths)"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "f6127d06d1e74c21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T12:37:52.231865Z",
     "start_time": "2024-05-28T12:37:52.193654Z"
    }
   },
   "source": [
    "# Prepare DataLoaders\n",
    "train_loader, valid_loader, test_loader = prepare_dataloaders(data_dirs, batch_size=16)\n",
    "\n",
    "# Debugging: Print a few batches from the train_loader to check the data\n",
    "# for images, labels in train_loader:\n",
    "    # print(\"Batch of images:\", images.shape)\n",
    "    # print(\"Batch of labels:\", labels)\n",
    "    # Print example of unpacked labels\n",
    "    # for label in labels:\n",
    "        # print(\"Label:\", label)\n",
    "    # break  # Print only the first batch"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T10:57:43.211279Z",
     "start_time": "2024-05-22T10:57:43.086111Z"
    }
   },
   "source": [
    "model = Model(num_channels=3, num_classes=4)\n",
    "trainer = ModelTrainer(model, train_loader, val_loader=valid_loader, learning_rate=0.001)\n",
    "trainer.train(num_epochs=10)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdad436d41a49441",
   "metadata": {},
   "source": [
    "inference = Inference(model, test_loader)\n",
    "inference.run_inference(num_samples=10)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "02df15f6-7bc7-4042-9ff6-88f399b48de4",
   "metadata": {},
   "source": [
    "# TFlite export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d1c2688-fcb2-4660-8efd-f0e884edb9ef",
   "metadata": {},
   "source": [
    "import ai_edge_torch"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cbfc6f-5023-46f3-bdf1-8ff34e922e53",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
